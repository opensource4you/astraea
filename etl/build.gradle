/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
plugins {
    // Apply the scala Plugin to add support for Scala.
    id 'scala'
}

repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}

def versions = [
        scala: project.properties['scala.version'] ?: "2.13.7",
        spark_sql: project.properties['spark_sql.version'] ?: "3.3.0",
        spark_kafka: project.properties['spark_kafka.version'] ?: "3.3.0",
        junit: project.properties['junit.version'] ?: "5.8.2",
        scalatest: project.properties['scalatest.version'] ?: "3.1.1",
        opencsv: project.properties['opencsv.version'] ?: "4.1",
        kafka: project.properties['kafka.version'] ?: "3.2.1"
]

dependencies {
    implementation "org.scala-lang:scala-library:${versions["scala"]}"
    implementation "org.apache.spark:spark-sql_2.13:${versions["spark_sql"]}"
    implementation "org.apache.spark:spark-sql-kafka-0-10_2.13:${versions["spark_kafka"]}"
    implementation "org.apache.kafka:kafka-clients:${versions["kafka"]}"

    testImplementation "org.scalatest:scalatest_2.13:${versions["scalatest"]}"
    testImplementation "org.junit.jupiter:junit-jupiter:${versions["junit"]}"
    testImplementation "com.opencsv:opencsv:${versions["opencsv"]}"
    testImplementation project(':common')
}

ext {
    numberOfForks = project.hasProperty('maxParallelForks') ? maxParallelForks.toInteger() : Math.max((int) (Runtime.runtime.availableProcessors() / 2), 1)
}

archivesBaseName = "astraea-etl"

tasks.named('test') {
    // Use JUnit Platform for unit tests.
    useJUnitPlatform()

    maxParallelForks = numberOfForks
    // make isolation for tests. It may be expensive but stability is first choice.
    forkEvery = 1
    testLogging {
        events "PASSED", "STARTED", "FAILED", "SKIPPED"
        exceptionFormat = 'full'
    }

    minHeapSize = "512m"
    maxHeapSize = "2048m"
}