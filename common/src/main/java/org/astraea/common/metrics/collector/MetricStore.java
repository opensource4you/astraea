/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.astraea.common.metrics.collector;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.concurrent.CompletionStage;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.ConcurrentSkipListSet;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.function.BiConsumer;
import java.util.function.Predicate;
import java.util.function.Supplier;
import java.util.stream.Collectors;
import org.astraea.common.Utils;
import org.astraea.common.consumer.Consumer;
import org.astraea.common.consumer.ConsumerConfigs;
import org.astraea.common.consumer.Deserializer;
import org.astraea.common.consumer.Record;
import org.astraea.common.cost.NoSufficientMetricsException;
import org.astraea.common.metrics.BeanObject;
import org.astraea.common.metrics.BeanQuery;
import org.astraea.common.metrics.ClusterBean;
import org.astraea.common.metrics.HasBeanObject;
import org.astraea.common.metrics.MBeanClient;
import org.astraea.common.metrics.MBeanRegister;
import org.astraea.common.metrics.Sensor;
import org.astraea.common.metrics.stats.Sum;

public interface MetricStore extends AutoCloseable {

  static Builder builder() {
    return new Builder();
  }

  /**
   * @return the {@link ClusterBean} is composed by a bunch of metrics generated by {@link
   *     MetricSensor}
   */
  ClusterBean clusterBean();

  /**
   * @return the latest fetched identities
   */
  Set<Integer> identities();

  /**
   * @return the last used sensors
   */
  Map<MetricSensor, BiConsumer<Integer, Exception>> sensors();

  /** Wait for the checker to be true or timeout. */
  void wait(Predicate<ClusterBean> checker, Duration timeout);

  @Override
  void close();

  interface Receiver extends AutoCloseable {

    static MetricFetcher.Sender local() {
      return LocalSenderReceiver.of();
    }

    static Receiver fixed(Map<Integer, Collection<BeanObject>> beans) {
      return new Receiver() {
        private final AtomicBoolean done = new AtomicBoolean(false);

        @Override
        public Map<Integer, Collection<BeanObject>> receive(Duration timeout) {
          return done.compareAndSet(false, true) ? beans : Map.of();
        }

        @Override
        public void close() {
          done.set(true);
        }
      };
    }

    /**
     * Using an embedded fetcher build the receiver. The fetcher will keep fetching beans
     * background, and it pushes all beans to store internally.
     */
    static Receiver local(Supplier<CompletionStage<Map<Integer, MBeanClient>>> clientSupplier) {

      var cache = LocalSenderReceiver.of();
      var fetcher = MetricFetcher.builder().clientSupplier(clientSupplier).sender(cache).build();
      return new Receiver() {
        @Override
        public Map<Integer, Collection<BeanObject>> receive(Duration timeout) {
          return cache.receive(timeout);
        }

        @Override
        public void close() {
          fetcher.close();
        }
      };
    }

    static Receiver topic(String bootstrapServer) {
      String METRIC_TOPIC = "__metrics";
      var consumer =
          Consumer.forTopics(Set.of(METRIC_TOPIC))
              .bootstrapServers(bootstrapServer)
              .config(
                  ConsumerConfigs.AUTO_OFFSET_RESET_CONFIG,
                  ConsumerConfigs.AUTO_OFFSET_RESET_EARLIEST)
              .keyDeserializer(Deserializer.INTEGER)
              .valueDeserializer(Deserializer.BEAN_OBJECT)
              .build();
      return new Receiver() {
        @Override
        public Map<Integer, Collection<BeanObject>> receive(Duration timeout) {
          return consumer.poll(timeout).stream()
              .collect(
                  Collectors.groupingBy(
                      Record::key,
                      Collectors.mapping(Record::value, Collectors.toCollection(ArrayList::new))));
        }

        @Override
        public void close() {
          consumer.close();
        }
      };
    }

    Map<Integer, Collection<BeanObject>> receive(Duration timeout);

    @Override
    default void close() {}
  }

  class Builder {

    // default impl returns all input metrics
    private Supplier<Map<MetricSensor, BiConsumer<Integer, Exception>>> sensorsSupplier =
        () ->
            Map.of(
                (MetricSensor)
                    (client, bean) ->
                        client.beans(BeanQuery.all()).stream()
                            .map(bs -> (HasBeanObject) () -> bs)
                            .toList(),
                (id, ignored) -> {});

    private Collection<Receiver> receivers;
    private Duration beanExpiration = Duration.ofSeconds(10);

    public Builder sensorsSupplier(
        Supplier<Map<MetricSensor, BiConsumer<Integer, Exception>>> sensorsSupplier) {
      this.sensorsSupplier = sensorsSupplier;
      return this;
    }

    public Builder receivers(Collection<Receiver> receivers) {
      this.receivers = receivers;
      return this;
    }

    public Builder beanExpiration(Duration beanExpiration) {
      this.beanExpiration = beanExpiration;
      return this;
    }

    public MetricStore build() {
      return new MetricStoreImpl(
          Objects.requireNonNull(sensorsSupplier, "sensorsSupplier can't be null"),
          Utils.requireNonEmpty(receivers, "receivers can't be empty"),
          Objects.requireNonNull(beanExpiration, "beanExpiration can't be null"));
    }
  }

  class MetricStoreImpl implements MetricStore {
    public static final String DOMAIN_NAME = "org.astraea";
    public static final String TYPE_PROPERTY = "type";
    public static final String TYPE_VALUE = "metricStore";
    public static final String NAME_PROPERTY = "name";
    public static final String BEAN_COUNT_NAME = "BeanCount";
    public static final String BEAN_RECEIVE_NAME = "BeanReceived";
    public static final String ID_PROPERTY = "id";
    public static final String COUNT_PROPERTY = "count";
    public static final String SUM_PROPERTY = "sum";

    private final Map<Integer, Collection<HasBeanObject>> beans = new ConcurrentHashMap<>();

    private final AtomicBoolean closed = new AtomicBoolean(false);

    private final Collection<Receiver> receivers;

    private final ExecutorService executor;

    // cache the latest cluster to be shared between all threads.
    private volatile ClusterBean lastClusterBean = ClusterBean.EMPTY;

    // trace the identities of returned metrics
    private final Set<Integer> identities = new ConcurrentSkipListSet<>();

    private volatile Map<MetricSensor, BiConsumer<Integer, Exception>> lastSensors = Map.of();
    // Thread ids and latches for detecting cluster bean changing.
    private final Map<Long, CountDownLatch> waitingList = new ConcurrentHashMap<>();
    // For mbean register. To distinguish mbeans of different metricStore.
    private final String uid = Utils.randomString();
    private final Sensor<Long> beanReceivedSensor =
        Sensor.builder().addStat(SUM_PROPERTY, Sum.ofLong()).build();

    private MetricStoreImpl(
        Supplier<Map<MetricSensor, BiConsumer<Integer, Exception>>> sensorsSupplier,
        Collection<Receiver> receivers,
        Duration beanExpiration) {
      this.receivers = receivers;
      // receiver + cleaner
      this.executor = Executors.newFixedThreadPool(2);

      Runnable cleanerJob =
          () -> {
            while (!closed.get()) {
              try {
                var before = System.currentTimeMillis() - beanExpiration.toMillis();
                var needUpdate =
                    this.beans.values().stream()
                        .map(
                            beans ->
                                beans.removeIf(
                                    hasBeanObject -> hasBeanObject.createdTimestamp() < before))
                        .collect(Collectors.toSet());
                if (needUpdate.contains(true)) updateClusterBean();
                TimeUnit.MILLISECONDS.sleep(beanExpiration.toMillis());
              } catch (Exception e) {
                // TODO: it needs better error handling
                e.printStackTrace();
              }
            }
          };
      Runnable receiverJob =
          () -> {
            var isChecking = new AtomicBoolean(false);
            var needChecking = new AtomicBoolean(false);
            while (!closed.get()) {
              try {
                receivers.stream()
                    // TODO: Busy waiting on metric receiving.
                    // issue: https://github.com/skiptests/astraea/issues/1834
                    // To prevent specific receiver block other receivers' job, we set receive
                    // timeout to zero. But if all receivers return empty immediately, it may cause
                    // this thread busy waiting on doing `receiver.receive`.
                    .map(r -> r.receive(Duration.ZERO))
                    .forEach(
                        allBeans -> {
                          beanReceivedSensor.record(
                              allBeans.values().stream().mapToLong(Collection::size).sum());
                          identities.addAll(allBeans.keySet());
                          lastSensors = sensorsSupplier.get();
                          allBeans.forEach(
                              (id, bs) -> {
                                var client = BeanObjectClient.of(id, bs);
                                var clusterBean = clusterBean();
                                lastSensors.forEach(
                                    (sensor, errorHandler) -> {
                                      try {
                                        beans
                                            .computeIfAbsent(
                                                id, ignored -> new ConcurrentLinkedQueue<>())
                                            .addAll(sensor.fetch(client, clusterBean));
                                      } catch (Exception e) {
                                        errorHandler.accept(id, e);
                                      }
                                    });
                              });
                          if (!allBeans.isEmpty()) {
                            // generate new cluster bean
                            updateClusterBean();
                            // Tell all waiting threads that cluster bean has been changed
                            this.waitingList.values().forEach(CountDownLatch::countDown);
                          }
                        });
              } catch (Exception e) {
                // TODO: it needs better error handling
                e.printStackTrace();
              }
            }
          };
      executor.execute(cleanerJob);
      executor.execute(receiverJob);

      // ------------ MBean register ------------
      MBeanRegister.local()
          .domainName(DOMAIN_NAME)
          .property(TYPE_PROPERTY, TYPE_VALUE)
          .property(ID_PROPERTY, uid)
          .property(NAME_PROPERTY, BEAN_COUNT_NAME)
          .attribute(
              COUNT_PROPERTY,
              Long.class,
              () -> beans.values().stream().mapToLong(Collection::size).sum())
          .description("The number of beans stored in this metricStore.")
          .register();
      MBeanRegister.local()
          .domainName(DOMAIN_NAME)
          .property(TYPE_PROPERTY, TYPE_VALUE)
          .property(ID_PROPERTY, uid)
          .property(NAME_PROPERTY, BEAN_RECEIVE_NAME)
          .attribute(SUM_PROPERTY, Long.class, () -> beanReceivedSensor.measure(SUM_PROPERTY))
          .description("The total number of beans received.")
          .register();
    }

    @Override
    public ClusterBean clusterBean() {
      return lastClusterBean;
    }

    @Override
    public Set<Integer> identities() {
      return Set.copyOf(identities);
    }

    @Override
    public Map<MetricSensor, BiConsumer<Integer, Exception>> sensors() {
      return Map.copyOf(lastSensors);
    }

    @Override
    public void close() {
      closed.set(true);
      executor.shutdownNow();
      Utils.packException(() -> executor.awaitTermination(30, TimeUnit.SECONDS));
      receivers.forEach(Receiver::close);
    }

    /**
     * User thread will "wait" until checker pass or timeout. First, register a latch to the waiting
     * list. Second run the checker with current clusterBean. If the checker passes, done.
     * Otherwise, wait for the cluster bean changing (/the latch counted down) and try again.
     */
    @Override
    public void wait(Predicate<ClusterBean> checker, Duration duration) {
      long timeout = System.currentTimeMillis() + duration.toMillis();
      var threadId = Thread.currentThread().getId();
      // For first check, we don't need to wait.
      var latch = new CountDownLatch(0);
      try {
        while (System.currentTimeMillis() < timeout) {
          try {
            // Wait for clusterBean being updated
            if (!latch.await(timeout - System.currentTimeMillis(), TimeUnit.MILLISECONDS)) {
              throw new IllegalStateException("Timeout waiting for the checker");
            }
            // Add new latch for detecting clusterBean updated
            latch = new CountDownLatch(1);
            this.waitingList.put(threadId, latch);

            // Return if check pass.
            if (checker.test(clusterBean())) return;
          } catch (NoSufficientMetricsException e) {
            // Check failed. Try again next time.
          } catch (InterruptedException ie) {
            throw new IllegalStateException("Interrupted while waiting for the checker");
          }
        }
        throw new IllegalStateException("Timeout waiting for the checker");
      } finally {
        this.waitingList.remove(threadId);
      }
    }

    private void updateClusterBean() {
      lastClusterBean =
          ClusterBean.of(
              beans.entrySet().stream()
                  .filter(entry -> !entry.getValue().isEmpty())
                  .collect(
                      Collectors.toUnmodifiableMap(
                          Map.Entry::getKey, e -> List.copyOf(e.getValue()))));
    }
  }
}
