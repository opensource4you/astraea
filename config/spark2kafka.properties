#Parameters you must configure
#==============================================================
#The data source path should be a directory.
source.path =

#The CSV Column Name.For example:sA=string,sB=integer,sC=boolean...
column.names =

#Primary keys.For example:sA=string,sB=integer,sC=boolean...
primary.keys =

#The Kafka bootstrap servers
kafka.bootstrap.servers =

#Set your topic name.
topic.name =

#Spark checkpoint path
checkpoint =

#Parameters that can be selected for configuration
#==============================================================

#Set the number of topic partitions, if it is empty that will set it to 15.
topic.partitions =

#Set the number of topic replicas, if it is empty that will set it to 1.
topic.replicas =

#The rest of the topic can be configured parameters.For example: keyA=valueA,keyB=valueB,keyC=valueC...
topic.config =

#Option to clean up completed files after processing.Available options are "archive", "delete", "off". Default:delete
clean.source =

#You must config it when clean.source set archive.
archive.path = 

#recursive.file is used to recursively load files. Default:true
recursive.file =
