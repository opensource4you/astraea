/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
plugins {
    id 'java'
}

apply from: "$rootDir/gradle/dependencies.gradle"

repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}
dependencies {
    testImplementation libs["junit"]
    testImplementation project(':it')

    implementation(project(':common')) {
        // those dependencies are not used by fs module
        exclude group: "org.apache.kafka"
        exclude group: "com.fasterxml.jackson.datatype"
        exclude group: "org.slf4j"
    }
    implementation libs["commons-net"]
    implementation(libs["hadoop-common"]) {
        // Kafka connector uses org.glassfish.jersey(2.34) which is conflict with com.sun.jersey(1.19).
        // Hence, the later must be excluded from hadoop dependencies to make embedded Kafka worker work
        exclude group: "com.sun.jersey"
    }

    //following dependencies are used for hdfs connector
    implementation libs["commons-logging"]
    implementation libs["hadoop-client-api"]
    implementation libs["hadoop-client-runtime"]
}

java {
    sourceCompatibility = 17
    targetCompatibility = 17
}

ext {
    numberOfForks = project.hasProperty('maxParallelForks') ? maxParallelForks.toInteger() : Math.max((int) (Runtime.runtime.availableProcessors() / 2), 1)
}

archivesBaseName = "astraea-fs"

tasks.named('test') {
    // Use JUnit Platform for unit tests.
    useJUnitPlatform()

    maxParallelForks = numberOfForks
    // make isolation for tests. It may be expensive but stability is first choice.
    forkEvery = 1
    testLogging {
        events "PASSED", "STARTED", "FAILED", "SKIPPED"
        exceptionFormat = 'full'
    }

    minHeapSize = "1024m"
    maxHeapSize = "2048m"
}